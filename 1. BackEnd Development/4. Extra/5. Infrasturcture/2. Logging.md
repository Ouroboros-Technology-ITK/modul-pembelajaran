
NEURONS Course Assignment Leaderboard Activity
Infrastructure
Logging
0-
Muhammad N
Kubernetes
Logging
Monitoring
Backend Rea⚫ 6 min read
Ketika kita telah melakukan deployment aplikasi, tentu kita merasa senang karena pekerjaan kita telah dapat dinikmati oleh user. Tapi bagaimana ternyata kalau fitur yang kita develop terdapat bug yang belum ditest sebelumnya atau terdapat incident yang terjadi. Tentu kita perlu melakukan debug pada environment production.
Setup Log
Debug pada environment production? bagaimana ya? apa bisa connect VS Code debugger ke aplikasi kita? Mungkin bisa, tapi itu akan membuat request yang diterima user menjadi keblock debugger kita dan user mendapatkan response yang lama.
Salah satu cara debug yang paling sederhana yaitu dengan print(namaVariable). Tapi jika terdapat banyak log debug ketika development muncul pada production, tentu akan semakin susah untuk mencari (tapi bisa jadi diperlukan). Pada library Logrus, kita dapat mengubah log level yang ditampilkan sesuai yang kita define.
logrus.SetLevel (logrus. InfoLevel) // set level
logrus.Infof("information for general request") logrus.Debugf("debug data for development") logrus.Errorf("error on payload %v", payload)
const (
>
// PanicLevel level, highest level of severity. Logs and then calls panic with the // message passed to Debug, Info, ...
PanicLevel Level = iota
// FatalLevel level. Logs and then calls logger. Exit(1)`. It will exit even if the // logging level is set to Panic.
FatalLevel
// ErrorLevel level. Logs. Used for errors that should definitely be noted.
// Commonly used for hooks to send errors to an error tracking service. ErrorLevel
// WarnLevel level. Non-critical entries that deserve eyes.
WarnLevel
// InfoLevel level. General operational entries about what's going on inside the // application.
InfoLevel
// DebugLevel level. Usually only enabled when debugging. Very verbose logging. DebugLevel
// TraceLevel level. Designates finer-grained informational events than the Debug. TraceLevel
Logrus dapat melakukan set maximum level yang akan ditampilkan kepada kita. Misal kita melakukan set level info, maka log level debug tidak akan ditampilkan dan log level error masih tetap ditampilkan.
Read Log
Di aplikasi production seringkali jumlah replica tidak hanya 1, apakah kita perlu melakukan cek 1 1 ke tiap replica? Untuk beberapa kasus iya, tapi bagaimana jika terdapat centralized log yang mengumpukan log log yang ada?
+σ & Not Secure 34.101.186.68:1601/kb/cor_greserve,value me from 2021-12-06T08:57:20.1702mode absolute to: 2021-12-06T08:32 42121 Save Open Share inspect CAuto-refresh kibana
December 6th 2021, 15:57:20.170 to December 6th 2021, 15:58:32.421 >
Available fields
Dev Took
tappname
December 6 2021, 15:57:28.170-December 2021, 155832421- Auto
www
December 6th 2821, 15:58:16.800 g time-2823-12-46788:58:362" level-errer esg-"lessons.handler.error shoulderrer" container is 8428548cfcfbccad
76657_Logging
_Apps access_log Ple
cer 22, 15315.000 22-12-46758352 level-error lessons.handler.errer shoulder tale/leggingbo endraven-and-wicaksanantainer i B285cb8fcfcf9bdcbc79134815580061766157
tderr
cbr 62921, 15-3836.00 2823-12-46788:58:342 level-errer lessons.handler.errer shoulderrer" wr wicaksana 84285cccdbd4cb3c3835000017657 l/legging_b_1 December 6th 2821, 15:38:14.000 g 5 access log infl
December 6th 2021, 15:57:58.002825-12-46788:57:582 level-errar aglessons.handler.arrer shoulder-and-w ali__/logging st December 6th 2821, 15:57:55.000 84285A access log ind fla
o Collapse
Kita dapat menggunakan Kibana (dashboard) untuk melihat log, dengan ElasticSearch (database) sebagai tempat penyimpanan dan logic melakukan pencarian. Nah bagaimana mengarahkan log aplikasi kita ke ElasticSearch?
Salah satu cara yaitu menggunakan Logstash. Namun kita akan menggunakan Fluentd.
Fluentd memiliki beberapa cara deployment. Pada kubernetes bisa menggunakan DaemonSet. Namun untuk yang sederhana kita bisa menggunakan docker compose.
version: "3"
services:
web:
image: httpd
ports:
- "80:80"
links:
- fluentd
logging:
driver: "fluentd"
options:
fluentd-address: localhost: 24224
tag: httpd.access
fluentd:
build: ./fluentd
volumes:
- ./fluentd/conf:/fluentd/etc
links:
- "elasticsearch"
ports:
- "24224:24224"
- "24224:24224/udp"
elasticsearch:
image: docker.elastic.co/elasticsearch/elasticsearch:7.13.1
container_name: elasticsearch
environment:
- "discovery.type=single-node"
expose:
- "9200"
ports:
- "9200:9200"
kibana:
image: docker.elastic.co/kibana/kibana:7.13.1
links:
- "elasticsearch"
ports:
- "5601:5601"
#fluentd/Dockerfile
FROM fluent/fluentd: v1.12.0-debian-1.0
USER root
RUN ["gem", "install", "fluent-plugin-elasticsearch", "--no-document", "--version", "5.0.3"] USER fluent
#fluentd/conf/fluent.conf
<source>
@type forward
port 24224
bind 0.0.0.0
</source>
<match *.**>
@type copy
<store>
@type elasticsearch
host elasticsearch
port 9200
logstash_format true
logstash_prefix fluentd
logstash_dateformat %Y%m%d
include_tag_key true
type_name access_log
tag_key @log_name flush_interval 1s
</store>
<store>
@type stdout
</store>
</match>
Siapkan file-file di atas dan jalankan docker-compose up, akses aplikasi, dan lihat di Kibana.
Learning Materials
• DEBUG MASALAH PADA APLIKASI - YouTube
• GitHub - sirupsen/logrus: Structured, pluggable logging for Go.
• Container Deployment - Fluentd
Assigments
• Lokasi assignments: apps/devops/logging
Application Development
Lengkapi main.go dengan logrus dan taruh beberapa log dengan terdapat log debug, error, dan info.
Observation
• Lengkapi docker-compose.yaml (atau bisa menggunakan cara lain) dengan label app-name berisikan nama kalian.
• ElasticSearch dan Kibana sudah tersedia pada server. IP address dan password akan diberikan.
• Lakukan request ke endpoint yang ada pada aplikasi.
• Lakukan observasi dengan melakukan filter pada Kibana, baik dari app-name, jenis log error, atau berdasarkan nama endpoint, dan berikan screenshot hasil observasi. Attach screenshot tersebut di Pull Request description.
< PREV
© 2022 Ruangguru. All Rights Reserved PT. Ruang Raya Indonesia
NEXT >