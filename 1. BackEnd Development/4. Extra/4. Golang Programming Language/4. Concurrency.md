
NEURONS Course Assignment Leaderboard Activity
Programming Language
Golang
Unit Test
Concurrency
Backend Rea⚫ 17 min read
0-
Muhammad N
Data Structure
Concurrency
Why Concurrency?
Concurrency umumnya digunakan untuk mengoptimalkan I/O bound process, di mana CPU terblock oleh I/O proses yang lama.
1 core CPU hanya bisa execute 1 instruction di saat yang sama. Sehingga jika kita membuat proses yang lama, maka CPU akan terblock
Contoh:
Memory Address
Memory - RAM
001
CPU
002
003
Program Counter PC
004
Instruction 1 Instruction 1 Instruction 2 Instruction 3
Computer Program
Instruction 1
Instruction 2
005
Instruction 3
001
Instruction 3
006
Instruction 3
Instruction 4
Initiated Fetch
007
Instruction 4
Instruction 5
008
Instruction 5
Instruction 6
Increment PC By 1
009
Instruction 6
Instruction 7
Instruction Register IR
010
Instruction 6
Instruction 8
011
Instruction 7
Instruction 1
012
Instruction 8
Instruction 1 Fetched into IR
www.learncomputerscienceonline.com
longRunningAPICall := func() { // API call }
longRunningDBCall := func() { // DB call }
apiRes = longRunningAPICall() // kita menunggu API Call selesai
dbRes = longRunningDBCall() // DB call hanya terjadi setelah API Call selesai
res: merge(apiRes, dbRes)
Kode di atas tidak optimal karena CPU tidak melakukan apapun selama proses I/O
Concurrency vs Parallelism
Perlu dibedakan antara concurrency dan parallelism. Concurrency adalah pseudo parallelism: instruction set tetap dijalankan secara sequential, namun CPU melakukan context switching sehingga instruction sets tersebut interleaved sehingga terlihat seolah-olah berjalan secara paralel. Concurrency bisa jalan di 1 CPU, sementara parallelism memerlukan >1 CPU (masing-masing memiliki Program Counter yang berbeda).
Thread vs Process
code
data
files
code
data
files
registers
counter
stack
registers
registers
registers
m
stack
stack
stack
thread
counter
counter
counter
Single-threaded process
Multi-threaded process
thread
Embarrassingly Parallel
Golang memiliki green thread yang disebut goroutine. Bisa dibayangkan ini seperti thread tapi jauh lebih cheap (Golang multiplex banyak goroutines dalam 1 thread). Kita bisa aman membuat ratusan ribu goroutine.
Untuk membuat goroutine, cukup menambahkan go keyword ketika memanggil function From:
numbers := make([]int, 1000000)
for i = 0; i < len(numbers); i++ {
numbers[i]= fibonacci(i)
}
To:
numbers := make([]int, 1000000)
for i = 0; i < len (numbers); i++ {
//it's important to capture i closure
go func(i int) {
numbers[i] fibonacci(i)
}(i) }
Code di atas akan menjalankan 1 juta goroutine di mana masing-masing melakukan komputasi fibonacci secara independent. Jika kita memiliki multiple CPU, goroutine tersebut bisa jalan secara parallel.
Perhatikan bahwa tidak ada sharing data antara goroutine di atas. Sehingga memang sangat straighforward untuk membuatnya concurrent. Problem seperti ini dinamakan Embarrassingly Parallel. Kembali ke code pertama di atas, mari kita optimize dengan menambahkan go :
go longRunningAPICall()
go longRunningDBCall()
res := ?
longRunningAPICall dan longRunningDBCall akan jalan concurrent. Namun ada masalah di sini, bagaimana res mendapatkan value dari 2 threads tersebut?
Sharing by communicating
//java
int a = 2
new Thread(() => { a = 3 }).start()
new Thread(() => { a = 4 }).start()
Di code tersebut, ada common variable yang dishare: a. Masalah yang sering muncul dengan sharing variable adalah kita perlu menjaga consistencynya dari data race.
Race Condition
int a = 0
for i = 0; i < 1000; i++ {
go func() {
a++
}0
}
time.Sleep(5⚫ time.Second)
fmt.Println(a) //?
Berapa kah nilai akhir a? Kita tidak tahu (undeterministic), tergantung bagaimana timing threads tersebut interleaved.
Hal ini terjadi karena operasi ++ tidak atomic.
Ini adalah classic problem di Shared Memory model: kita perlu menjaga konsistensi data variable yang dishare multiple threads. Di Java kita perlu guard perubahan data di dalam synchronized block:
//java
class Counter {
private int a = 0;
public void increment() {
//multiple threads can access this block
//do something
synchronized (this) {
//only 1 thread can run in this block
a++
}
//multiple threads can access this block //do something
}
}
public static void main(String[] args) {
Counter = new Counter();
new Thread(() -> {
for (int i = 0; i < 1000; i++) {
c.increment();
}
}).start();
}
Yang dilakukan oleh synchronized block di atas adalah membuat proses a++ jalan secara serial: 1 thread dalam satu waktu. Potential problem dari model ini:
• Kita perlu memastikan semua perubahan data harus diguard oleh synchronized block
• Karena code di dalam synchronized jalan sequentially, kita perlu menjaga bagian ini seminim mungkin (jika aman jalan parallel, jangan dimasukkan ke dalam synchronized block)
Atomic Operation
Untuk operasi simple seperti ++, kita bisa menggunakan atomic operation dari sync/atomic:
int a = 0
for i = 0; i < 1000; i++ {
go func() {
atomic.AddInt32(&a, 1)
}0
}
These functions require great care to be used correctly. Except for special, low-level applications, synchronization is better done with channels or the facilities of the sync package. Share memory by communicating; don't communicate by sharing memory.
CSP
Don't communicate by sharing memory; share memory by communicating. (R. Pike)
Berbeda dengan classical Java, concurrency communication di Go berdasarkan concept CSP. Goroutine berkoordinasi/bertukar data dengan cara mengirimkan datanya, bukan mengakses memory address yang
sama
go func(a chan int) { a <- 3 }(
go func(a chan int) { a <- 4 }(
Di code tersebut, koordinasinya terjadi dari proses komunikasi melalui chan int. Bayangkan channel seperti kotak surat yang menampung message yang kita kirimkan dan kita terima. Pengirim surat dan penerima surat tidak pernah memegang surat yang sama secara bersamaan.
Untuk mengirim data ke channel, gunakan channel <-. Dan gunakan <- channel untuk mengambilnya.
apichan make (chan []string) dbChan := make(chan []string)
longRunningAPICall := func() {
//assume this take a long time apiChan <- []string{"a", "b", "c"}
}
longRunningDBCall := func() {
}
//assume this take a long time
dbChan<[]string{"d", "e", "f"}
go longRunningAPICall(apiChan)
go longRunningDBCall(dbChan)
apiRes<-apichan
dbRes<-dbChan
res = merge(apiRes, dbRes)
apiRes dan dbRes akan menunggu surat masuk ke apichan dan dbChan respectively. longRunningAPICall dan longRunningDBCall tetap bisa jalan concurrently. Dan tidak ada single memory address yang dishare oleh 2 threads tersebut.
Channel
Untuk channel dengan size 0, both operasi <-dan-> blocking:
c = make(chan int)
C <- 0
//this code never executed
c = make(chan int)
a := <- c
//this code never executed
Bayangkan seperti kotak surat yang ukurannya sangat kecil (0) sehingga pengirim surat perlu menunggu (dan terus menunggu) hingga penerima surat mengambilnya ( c <- "hi" ). Dan penerima surat juga menunggu (dan terus menunggu) hingga pengirim surat mengirimkan surat (<- c).
Apakah zero sized channel tidak berguna? Tidak, justru sangat berguna untuk synchronizing goroutine (dan untuk sebagian besar kebutuhan).
result = make(chan int)
go func() {
// do expensive calculation here
result < 3.1415926535897932384626433832795028841971693993751
// this part waits until the result is consumed
}0
//can do other work here
//...
//ok, now let's wait for the result
//this is blocked until a data is put into result channel fmt.Println(<-result)
Buffered Channel
Kita bisa membuat channel dengan size yang lebih besar dari 0.
C = make(chan int, 1)
Bayangkan seperti kotak surat yang memiliki kapasitas n surat. Jika kapasitas itu belum terlampaui, operasi c <- tidak akan blocking. Hanya ketika sudah penuh, operasi c <- blocking. Sementara untuk operasi <- c, jika tidak ada data yang tersedia, akan blocking.
Seperti pengirim surat yang akan menunggu hanya jika kotak surat penuh. Dan penerima surat yang hanya akan menunggu jika tidak ada surat.
c = make(chan int, 1)
c<- 1 //not blocked
c <- 2 //blocked
Background Worker
Untuk task yang repetitive, kita bisa gunakan worker pattern & buffered channel:
imageQueue:= make(chan string, 100)
imageResizer := func() {
//infinite loop
for {
image <-imageQueue
// do something
}
}
go imageResizer()
//common business logic
//when we need to resize image, we can just put it into the queue
imageQueue <- "image.jpg"
imageQueue<- "image2.jpg"
Worker Termination
Bagaimana jika worker tersebut tidak ingin long lived? Bagaimana cara terminate infinite loopnya? Bisa gunakan close
imageQueue make (chan string, 100)
imageResizer: func() {
for {
image, more := <-imageQueue
if !more {
break
}
// do something
}
}
go imageResizer()
imageQueue<- "image.jpg"
close(imageQueue)
Bisa juga menggunakan for ... range. for ... range akan terminate ketika channel tersebut di-
close.
imageQueue:= make(chan string, 100)
imageResizer := func() {
for image range imageQueue {
// do something
}
}
go imageResizer()
imageQueue< "image.jpg"
close(imageQueue)
Channel yang sudah diclose tidak bisa di-send data lagi (akan panic) dan akan nilai more di data, more = <-cakan menjadi false.
Select
Bagaimana jika ada multiple channels yang ingin diproses oleh satu worker? Katakan worker di atas ingin bisa resize image dan video (walaupun sebenarnya bisa juga membuat 2 workers)
imageQueue make (chan string, 100)
videoQueue:= make(chan string, 100)
quit make(chan bool)
resizer: func() {
for {
//blocked
image = <-imageQueue
//do something
video <-videoQueue
//do something
}
}
Code di atas buggy, ada potensi deadlock jika kita hanya mengirim videoQueue dan tidak pernah
mengirim imageQueue. Solusinya dengan select :
imageQueue: make (chan string, 100)
videoQueue:= make(chan string, 100)
quit:= make(chan bool)
resizer: func() {
for {
select {
case image
<-imageQueue:
// do something 1
// do something 2
// do something 3
case video:
<-videoQueue:
// do something 1
// do something 2
// do something 3
case <-quit:
break
}
}
}
go resizer()
imageQueue<"image.jpg"
videoQueue <- "video.mp4"
quit <- true
Generator
Generator adalah function yang mengembalikan channel
func primeGenerator() chan int {
ch
make(chan int)
go func() {
for i = 2;; i++ {
if isPrime(i) {
ch <- i
}
}
}0
return ch
}
primeChan primeGenerator()
fmt.Println(<-primeChan) // 2
fmt.Println(<-primeChan) // 3
fmt.Println(<-primeChan) // 5
Fan
In
Fan in adalah pattern yang menggabungkan multiple channel menjadi satu
func fanIn(c1 chan int, c2 chan int) chan int {
c = make(chan int)
go func() {
for {
select {
case v <-c1:
C <- V
case v <-c2:
C<- V
}
}
}0
return c
}
WaitGroup
Walaupun sebaiknya berbagi data antar goroutine sebaiknya menggunakan komunikasi (channel),
terkadang ada beberapa kasus yang lebih mudah (dan pendek) apabila langsung berbagi akses ke suatu variable. Salah satu contoh yang sering digunakan yaitu menunggu beberapa goroutine selesai.
var wg sync.WaitGroup
for i = 0; i < 10; i++ {
wg.Add(1)
go func() {
defer wg.Done()
longRunningAPICall()
}0
}
wg.Wait()
This code is equivalent:
var wg sync.WaitGroup
//this is more likely to product bug
//be careful to also change this 10 whenever the looping condition changes
wg.Add(10)
for i = 0; i < 10; i++ {
go func() {
defer wg.Done()
longRunningAPICall()
}0
}
wg.Wait()
wg.Wait() akan menunggu nilai wg bernilai 0. Nilai awal wg adalah 0, kemudian pada setiap loop mendapatkan increment berjumlah 1 (dari wg.Add(1) ). Pada setiap goroutine, terdapat wg. Done() yang akan dipanggil setelah pemanggilan API call selesai, yang akan melakukan decrement berjumlah 1. Sehingga ketika semua goroutine selesai, kita akan dapat melanjutkan operasi setelah wg.Wait(). Kita bisa juga implementasi hal di atas dengan channel (walaupun lebih panjang):
done = make(chan bool)
for i = 0; i < 10; i++ {
go func() {
defer func() { done <- true }()
longRunningAPICall()
}0
}
for i = 0; i < 10; i++ {
<-done
}
Berhati-hati meletakkan wg. Done(), pastikan hanya diletakkan ketika goroutine yang ditunggu sudah
selesai. Code berikut salah:
var wg sync.WaitGroup
for i = 0; i < 10; i++ {
wg.Add(1)
go func() {
longRunningAPICall()
}0
wg.Done() //bug
}
wg.Wait()
Mutex
Seperti halnya WaitGroup, ada kasus seperti ingin berbagi variable (bisa int, atau bahkan map). Bagian yang membaca dan mengubah nilai shared variable disebut dengan Critical Section. Kita ingin agar ketika sedang menggunakan variable tersebut, tidak ada goroutine lain yang akan menggunakan variable tersebut. Untuk menjaga Critical Section, kita bisa menggunakan mutex.
accountBalance := 5
var mu sync.Mutex
go func() {
mu.Lock()
defer mu.Unlock()
incrementValue = accountBalance + 1
accountBalance incrementValue
// do something
}0
go func() {
mu.Lock()
defer mu.Unlock()
decrementValue = accountBalance 1
// do something
accountBalance decrementValue
}0
Dengan menggunakan mu. Lock() dan mu.Unlock() pada bagian Critical Section, maka tidak
akan terjadi race condition yang menyebabkan nilai sharedVariable bernilai 4, 5 atau 6.
#1 LOAD 5
#1 ADD 6
#1 STORE 6
#2 LOAD 6
#2 MINUS 5
#2 STORE 5
Final Result: 5
#1 LOAD 5
#2
LOAD 5
#1 ADD 6
#2 MINUS 4
#2
STORE 4
#1 STORE 6
Final Result: 6
#1
LOAD 5
#2 LOAD 5
#1 ADD 6
#2
MINUS 4
#1
STORE 6
#2 STORE 4
Final Result: 4
Most Go newbies try to solve every concurrency problem using a channel as it is a cool feature of the
language. This is wrong. The language gives us the option to either use Mutex or Channel and there is no wrong in choosing either.
In general use channels when Goroutines need to communicate with each other and mutexes when
only one Goroutine should access the critical section of code.
Deadlock
Dengan beberapa cara concurrency di atas, terdapat kasus di mana tidak ada satu goroutine yang
menjalankan instruksi karena sedang menunggu hasil dari goroutine yang lain.
Contoh kasus deadlock pada mutex:
sharedVariable1 := &data{sharedData: 5, mu: &sync.Mutex{}}
sharedVariable2 := &data{sharedData: 5, mu: &sync.Mutex{}}
go func() {
}0
sharedVariable1.mu. Lock() // op1
// do something
sharedVariable2.mu. Lock() // op2
// do something
sharedVariable2.mu. Unlock() // op3
// do something
sharedVariable1.mu. Unlock() // op4
go func() {
sharedVariable2.mu. Lock() // op5
// do something
sharedVariable1.mu. Lock() // op6
// do something
sharedVariable1.mu. Unlock() // op7
// do something
sharedVariable2.mu. Unlock() // op8
}0
Apabila op5 dijalankan sebelum op2 dan dijalankan setelah op1, maka op2 perlu menunggu op8 dieksekusi terlebih dahulu. Namun op8 bisa tereksekusi apabila op6 dieksekusi. Sedangkan op6 bisa dieksekusi apabila op4 dieksekusi. Namun op4 bisa tereksekusi apabila op2 dieksekusi. Sehingga, kedua goroutine tersebut tidak dapat dieksekusi semua.
GOROUTINE1
GOROUTINE2
op1
op5
op2
op6
Deadlock
Deadlock
Tidak hanya mutex, deadlock juga dapat terjadi pada channel seperti pada contoh berikut:
channel1 = make(chan int)
channel2 = make(chan int)
go func() {
}0
channel1 < 1 // op1
// do something
<-channel2 // op2
go func() {
channel2 < 1 // op3
// do something
<-channel1 // op4
Code di atas mirip dengan kasus mutex, namun kita bisa menggunakan buffered channel, select
dengan context timeout untuk menghindari deadlock.
Learning Materials
• Wajib: Go Tour
• Go Concurrency Patterns, Slide
• Deadlock vs Starvation
Assignments
•
Lokasi assignments: libs/concurrency
•
Urutan pengerjaan yang direkomendasikan
⚫ goroutine_test.go
⚫waitgroup_test.go
•
mutex_test.go
•
errgroup_test.go
channel_test.go
⚫bufferredchannel_test.go
⚫ select_test.go
⚫close_test.go
Further Readings
• Concurrency vs Parallelism
• Advanced Go Concurrency Patterns, Slide
• Pipelines
• Context
• Golang Memory Model
• Race Detector
< PREV
2022 Ruangguru. All Rights Reserved PT. Ruang Raya Indonesia